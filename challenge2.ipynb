{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn.functional as F\n",
    "def train(model, device, train_loader, optimizer,  epoch,criterion=F.cross_entropy, display=True):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if display:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "          100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "EdgeNeXt\n",
      "seed 0\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.332071\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.790968\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.639425\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.642535\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.658128\n",
      "\n",
      "Test set: Average loss: 0.6493, Accuracy: 260/400 (65.00%)\n",
      "\n",
      "seed 1\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.490476\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.706816\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.584596\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.369609\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.239352\n",
      "\n",
      "Test set: Average loss: 0.2982, Accuracy: 358/400 (89.50%)\n",
      "\n",
      "seed 2\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.853681\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.442746\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.083004\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.043463\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.028486\n",
      "\n",
      "Test set: Average loss: 0.2428, Accuracy: 362/400 (90.50%)\n",
      "\n",
      "seed 3\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.486621\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.688380\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.505681\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.227302\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.088468\n",
      "\n",
      "Test set: Average loss: 0.5652, Accuracy: 301/400 (75.25%)\n",
      "\n",
      "seed 4\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.989480\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.666320\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.393181\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.195039\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.072271\n",
      "\n",
      "Test set: Average loss: 0.6204, Accuracy: 296/400 (74.00%)\n",
      "\n",
      "seed 5\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.308083\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.312412\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.130446\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.051937\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.030889\n",
      "\n",
      "Test set: Average loss: 0.5130, Accuracy: 328/400 (82.00%)\n",
      "\n",
      "seed 6\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.698860\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.486412\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.282232\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.130561\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.057400\n",
      "\n",
      "Test set: Average loss: 0.4309, Accuracy: 330/400 (82.50%)\n",
      "\n",
      "seed 7\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.589619\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.660846\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.069501\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.034276\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.022155\n",
      "\n",
      "Test set: Average loss: 0.2945, Accuracy: 353/400 (88.25%)\n",
      "\n",
      "seed 8\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.053628\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.182952\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.062580\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.034433\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.022792\n",
      "\n",
      "Test set: Average loss: 0.2989, Accuracy: 352/400 (88.00%)\n",
      "\n",
      "seed 9\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 6.230722\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.776915\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.660646\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.583817\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.338282\n",
      "\n",
      "Test set: Average loss: 1.1521, Accuracy: 243/400 (60.75%)\n",
      "\n",
      "seed 10\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.889006\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.082660\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.037218\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.023081\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.016469\n",
      "\n",
      "Test set: Average loss: 0.2139, Accuracy: 368/400 (92.00%)\n",
      "\n",
      "seed 11\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 6.151215\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.437536\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.165513\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.072413\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.039756\n",
      "\n",
      "Test set: Average loss: 1.1423, Accuracy: 242/400 (60.50%)\n",
      "\n",
      "seed 12\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 6.067660\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.542596\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.368499\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.113224\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.059078\n",
      "\n",
      "Test set: Average loss: 0.9212, Accuracy: 240/400 (60.00%)\n",
      "\n",
      "seed 13\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.840738\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.218647\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.072450\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.039389\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.026243\n",
      "\n",
      "Test set: Average loss: 0.5098, Accuracy: 316/400 (79.00%)\n",
      "\n",
      "seed 14\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.640383\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.236262\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.044784\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.024622\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.016758\n",
      "\n",
      "Test set: Average loss: 0.1828, Accuracy: 376/400 (94.00%)\n",
      "\n",
      "seed 15\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 6.366169\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.595092\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.483217\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.129766\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.059670\n",
      "\n",
      "Test set: Average loss: 0.7284, Accuracy: 279/400 (69.75%)\n",
      "\n",
      "seed 16\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.979163\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.370407\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.148613\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.054020\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.031536\n",
      "\n",
      "Test set: Average loss: 0.6890, Accuracy: 314/400 (78.50%)\n",
      "\n",
      "seed 17\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.467560\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.103868\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.032544\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.019112\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.013489\n",
      "\n",
      "Test set: Average loss: 0.4043, Accuracy: 341/400 (85.25%)\n",
      "\n",
      "seed 18\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 6.079478\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.469489\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.107461\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.051740\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.031660\n",
      "\n",
      "Test set: Average loss: 0.2305, Accuracy: 365/400 (91.25%)\n",
      "\n",
      "seed 19\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.150371\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.248617\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.056869\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.029609\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.019640\n",
      "\n",
      "Test set: Average loss: 0.4289, Accuracy: 340/400 (85.00%)\n",
      "\n",
      "seed 20\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.757581\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.199486\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.068155\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.036362\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.023777\n",
      "\n",
      "Test set: Average loss: 0.5202, Accuracy: 323/400 (80.75%)\n",
      "\n",
      "seed 21\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.766429\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.411967\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.188817\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.062931\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.039355\n",
      "\n",
      "Test set: Average loss: 0.6617, Accuracy: 288/400 (72.00%)\n",
      "\n",
      "seed 22\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.172098\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.406010\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.088999\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.048783\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.032171\n",
      "\n",
      "Test set: Average loss: 0.6254, Accuracy: 308/400 (77.00%)\n",
      "\n",
      "seed 23\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.149825\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.262181\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.063970\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.033278\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.022250\n",
      "\n",
      "Test set: Average loss: 0.6651, Accuracy: 301/400 (75.25%)\n",
      "\n",
      "seed 24\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.919440\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.542883\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.260997\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.086153\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.045453\n",
      "\n",
      "Test set: Average loss: 0.4611, Accuracy: 327/400 (81.75%)\n",
      "\n",
      "seed 25\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.093030\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.418170\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.119634\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.052504\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.030772\n",
      "\n",
      "Test set: Average loss: 0.9046, Accuracy: 262/400 (65.50%)\n",
      "\n",
      "seed 26\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.983750\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.145782\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.049706\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.029065\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.020389\n",
      "\n",
      "Test set: Average loss: 0.3084, Accuracy: 358/400 (89.50%)\n",
      "\n",
      "seed 27\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.967410\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.186594\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.048288\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.025389\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.016846\n",
      "\n",
      "Test set: Average loss: 0.4912, Accuracy: 341/400 (85.25%)\n",
      "\n",
      "seed 28\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.058695\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.190972\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.042167\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.023007\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.015423\n",
      "\n",
      "Test set: Average loss: 0.5123, Accuracy: 332/400 (83.00%)\n",
      "\n",
      "seed 29\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.715008\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.058798\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.023955\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.015098\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.011066\n",
      "\n",
      "Test set: Average loss: 0.1916, Accuracy: 375/400 (93.75%)\n",
      "\n",
      "seed 30\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.392982\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.050996\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.026676\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.018298\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.013930\n",
      "\n",
      "Test set: Average loss: 0.2770, Accuracy: 360/400 (90.00%)\n",
      "\n",
      "seed 31\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.378660\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.097760\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.038834\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.023314\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.016395\n",
      "\n",
      "Test set: Average loss: 0.1433, Accuracy: 380/400 (95.00%)\n",
      "\n",
      "seed 32\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.924097\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.265552\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.065604\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.031955\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.020271\n",
      "\n",
      "Test set: Average loss: 0.3790, Accuracy: 342/400 (85.50%)\n",
      "\n",
      "seed 33\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 4.898073\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.136756\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.054207\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.032861\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.023162\n",
      "\n",
      "Test set: Average loss: 0.6740, Accuracy: 289/400 (72.25%)\n",
      "\n",
      "seed 34\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.263999\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.080715\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.033136\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.020806\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.015148\n",
      "\n",
      "Test set: Average loss: 0.3388, Accuracy: 353/400 (88.25%)\n",
      "\n",
      "seed 35\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.322928\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.052699\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.025652\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.016981\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.012696\n",
      "\n",
      "Test set: Average loss: 0.1796, Accuracy: 378/400 (94.50%)\n",
      "\n",
      "seed 36\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.393682\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.276719\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.081716\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.039888\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.025572\n",
      "\n",
      "Test set: Average loss: 0.5178, Accuracy: 318/400 (79.50%)\n",
      "\n",
      "seed 37\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.604347\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.068211\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.028804\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.018104\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.013144\n",
      "\n",
      "Test set: Average loss: 0.1780, Accuracy: 372/400 (93.00%)\n",
      "\n",
      "seed 38\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.287094\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.031137\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.015300\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.010642\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.008286\n",
      "\n",
      "Test set: Average loss: 0.5213, Accuracy: 329/400 (82.25%)\n",
      "\n",
      "seed 39\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.191969\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.019854\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.010942\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.007872\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.006263\n",
      "\n",
      "Test set: Average loss: 0.1949, Accuracy: 379/400 (94.75%)\n",
      "\n",
      "seed 40\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 6.303843\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.305163\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.043645\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.023633\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.016128\n",
      "\n",
      "Test set: Average loss: 0.3729, Accuracy: 348/400 (87.00%)\n",
      "\n",
      "seed 41\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.813863\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.231312\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.062639\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.034291\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.022915\n",
      "\n",
      "Test set: Average loss: 0.6488, Accuracy: 294/400 (73.50%)\n",
      "\n",
      "seed 42\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 5.110338\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.343785\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.130467\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.054233\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.032948\n",
      "\n",
      "Test set: Average loss: 0.7810, Accuracy: 273/400 (68.25%)\n",
      "\n",
      "seed 43\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.938454\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.592337\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.059462\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.031421\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.020988\n",
      "\n",
      "Test set: Average loss: 0.4837, Accuracy: 322/400 (80.50%)\n",
      "\n",
      "seed 44\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 1.639442\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.019154\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.010910\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.007893\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.006272\n",
      "\n",
      "Test set: Average loss: 0.1716, Accuracy: 374/400 (93.50%)\n",
      "\n",
      "seed 45\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.074361\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.321233\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.071013\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.036855\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.023456\n",
      "\n",
      "Test set: Average loss: 0.2671, Accuracy: 358/400 (89.50%)\n",
      "\n",
      "seed 46\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 2.779562\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.047305\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.024327\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.016507\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.012523\n",
      "\n",
      "Test set: Average loss: 0.1906, Accuracy: 377/400 (94.25%)\n",
      "\n",
      "seed 47\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 4.511756\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.161219\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.027431\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.015799\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.011327\n",
      "\n",
      "Test set: Average loss: 0.1988, Accuracy: 373/400 (93.25%)\n",
      "\n",
      "seed 48\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 3.562824\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.080518\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.028347\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.017403\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.012688\n",
      "\n",
      "Test set: Average loss: 0.1750, Accuracy: 376/400 (94.00%)\n",
      "\n",
      "seed 49\n",
      "Num Samples For Training 50 Num Samples For Val 400\n",
      "Train Epoch: 0 [0/50 (0%)]\tLoss: 4.817619\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.052807\n",
      "Train Epoch: 20 [0/50 (0%)]\tLoss: 0.025816\n",
      "Train Epoch: 30 [0/50 (0%)]\tLoss: 0.017321\n",
      "Train Epoch: 40 [0/50 (0%)]\tLoss: 0.013043\n",
      "\n",
      "Test set: Average loss: 0.5012, Accuracy: 327/400 (81.75%)\n",
      "\n",
      "Acc over 5 instances: 82.50 +- 9.88 , time: 9.34\n",
      "Acc over 5 instances: 82.50 +- 9.88 , time:  9.34 +- 0.38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "torch.cuda.benchmark = True\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# We resize images to allow using imagenet pre-trained models, is there a better way?\n",
    "resize = transforms.Resize(224)\n",
    "\n",
    "transform_val = transforms.Compose([resize, transforms.ToTensor(), normalize]) #careful to keep this one same\n",
    "transform_train = transforms.Compose([resize, transforms.ToTensor(), normalize])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device) # you will really need gpu's for this part\n",
    "\n",
    "##### Cifar Data\n",
    "cifar_data = datasets.CIFAR10(root='.',train=True, transform=transform_train, download=True)\n",
    "\n",
    "#We need two copies of this due to weird dataset api\n",
    "cifar_data_val = datasets.CIFAR10(root='.',train=True, transform=transform_val, download=True)\n",
    "\n",
    "accs = []\n",
    "\n",
    "\n",
    "edgenext_xx_small = timm.create_model('edgenext_xx_small', pretrained=True, num_classes=10)\n",
    "\n",
    "classfiers = [ edgenext_xx_small]\n",
    "\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from timm.optim import SGDP\n",
    "\n",
    "def run(model):\n",
    "    print(model.__class__.__name__)\n",
    "    accs = np.array([])\n",
    "    times = np.array([])\n",
    "    losses = np.array([])   \n",
    "    model.to(device)\n",
    "    optimizer = SGDP(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
    "    \n",
    "    scheduler = CosineLRScheduler(optimizer, t_initial=5)\n",
    "    for seed in range(50):\n",
    "        print(\"seed\", seed)\n",
    "        prng = RandomState(seed)\n",
    "        random_permute = prng.permutation(np.arange(0, 5000))\n",
    "        classes =  prng.permutation(np.arange(0,10))\n",
    "        indx_train = np.concatenate([np.where(np.array(cifar_data.targets) == classe)[0][random_permute[0:25]] for classe in classes[0:2]])\n",
    "        indx_val = np.concatenate([np.where(np.array(cifar_data.targets) == classe)[0][random_permute[25:225]] for classe in classes[0:2]])\n",
    "\n",
    "        train_data = Subset(cifar_data, indx_train)\n",
    "        val_data = Subset(cifar_data_val, indx_val)\n",
    "\n",
    "        print('Num Samples For Training %d Num Samples For Val %d'%(train_data.indices.shape[0],val_data.indices.shape[0]))\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                                    batch_size=128,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                                batch_size=128,\n",
    "                                                shuffle=False)\n",
    "        \n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        start.record()\n",
    "        for epoch in range(50):\n",
    "            loss = train(model, device, train_loader, optimizer, epoch, display=epoch%10==0)\n",
    "            losses = np.append(losses, loss)\n",
    "            scheduler.step(loss)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        time = start.elapsed_time(end)\n",
    "        times = np.append(times, time)        \n",
    "        acc = test(model, device, val_loader)\n",
    "        accs = np.append(accs, acc)\n",
    "    print('Acc over 5 instances: %.2f +- %.2f , time: %.2f'%(accs.mean(),accs.std(), times.mean()/1000))    \n",
    "    return accs, times, losses\n",
    "\n",
    "metrics_map = {}\n",
    "for model in classfiers:\n",
    "    accs, times, losses = run(model)\n",
    "    print('Acc over 5 instances: %.2f +- %.2f , time:  %.2f +- %.2f'%(accs.mean(),accs.std(), times.mean()/1000, times.std()/1000))\n",
    "    metrics_map[model.__class__.__name__] = (accs, times, losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp691",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
